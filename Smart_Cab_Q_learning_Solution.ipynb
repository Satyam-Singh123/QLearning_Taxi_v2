{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Smart Cab_Q learning-Solution.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMBJSp_7W9iK",
        "colab_type": "text"
      },
      "source": [
        "## Smart_Cab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBlLcDgiW9iL",
        "colab_type": "text"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIjwWP9RW9iM",
        "colab_type": "code",
        "colab": {},
        "outputId": "64dbee79-fe2d-4f8a-8221-be4b9fb4d93a"
      },
      "source": [
        "import gym\n",
        "# Importing libraries\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "from collections import deque\n",
        "import collections\n",
        "import pickle\n",
        "#for text processing\n",
        "import spacy\n",
        "import re\n",
        "import pandas as pd\n",
        "env = gym.make(\"Taxi-v2\").env\n",
        "env.render()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|R: |\u001b[43m \u001b[0m: :\u001b[34;1mG\u001b[0m|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[35mY\u001b[0m| : |B: |\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY4Q4IpJW9iV",
        "colab_type": "code",
        "colab": {},
        "outputId": "9a4c3ba1-3a5e-4207-b2d6-7178c20a1b64"
      },
      "source": [
        "env.reset() # reset environment to a new, random state\n",
        "env.render()\n",
        "print(\"Action Space {}\".format(env.action_space))\n",
        "print(\"State Space {}\".format(env.observation_space))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : : : :\u001b[43m \u001b[0m|\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "\n",
            "Action Space Discrete(6)\n",
            "State Space Discrete(500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtSn1U9zW9iZ",
        "colab_type": "text"
      },
      "source": [
        "#### There are 4 locations (labeled by different letters), and our job is to pick up the passenger at one location and drop him off at another. We receive +20 points for a successful drop-off and lose 1 point for every time-step it takes. There is also a 10 point penalty for illegal pick-up and drop-off actions.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISNUPiRcW9ia",
        "colab_type": "text"
      },
      "source": [
        "### Mapping City"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnmZPdxvW9ic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_loc_dict(city_df):\n",
        "    loc_dict = {}\n",
        "    ## Create dictionary example, loc_dict['dwarka sector 23] = 0\n",
        "    for place , maps in zip(city_df.location, city_df.mapping):\n",
        "        loc_dict[place] = maps\n",
        "    return loc_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MX7p5teW9ig",
        "colab_type": "text"
      },
      "source": [
        "### Fetching Origing, Destination, and Time of Pickup from the sms data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffx0q8LwW9ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fetch_pickup_drop(text):\n",
        "    \n",
        "    s = text.lower()\n",
        "    if ('from' in s):\n",
        "        pick_pat = re.compile(r'from (airport|hauz khaas|dwarka sector 23|dwarka sector 21)')\n",
        "        origin = re.findall(pick_pat , s)[0] #Pick-up location of Passenger\n",
        "        time_pat = re.compile('at (\\w+ (pm|am))')\n",
        "        time_of_pickup = re.findall(time_pat,s)[0][0] #Time for Pick up\n",
        "        dest_pat = re.compile(r'(airport|hauz khaas|dwarka sector 23|dwarka sector 21)')\n",
        "        destination = [word for word in re.findall(dest_pat,s) if word!= origin][0]#Drop-off location of Passenger\n",
        "        \n",
        "    else:\n",
        "        dest_pat = re.compile(r'(to|for) (airport|hauz khaas|dwarka sector 23|dwarka sector 21)')\n",
        "        destination = re.findall(dest_pat , s)[0][-1]\n",
        "        time_pat = re.compile('at (\\w+ (pm|am))')\n",
        "        time_of_pickup = re.findall(time_pat,s)[0][0]\n",
        "        pick_pat = re.compile(r'(airport|hauz khaas|dwarka sector 23|dwarka sector 21)')\n",
        "        origin = [word for word in re.findall(pick_pat,s) if word != destination][0]\n",
        "        \n",
        "    return [origin, destination, time_of_pickup.upper()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLXWihW2W9il",
        "colab_type": "text"
      },
      "source": [
        "### Checking If Fetched Locations Value Matches With Original Data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LefrcNNZW9im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_pick_up_drop_correction(picks, drops, index, orig_df):\n",
        "    original_origin = orig_df.iloc[index]['origin']\n",
        "    original_destination = orig_df.iloc[index]['dest']\n",
        "    if original_origin == picks and original_destination == drops:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8uA3SvUW9iq",
        "colab_type": "text"
      },
      "source": [
        "## Summing up the Q-Learning Process\n",
        "Breaking it down into steps, we get\n",
        "\n",
        "Initialize the Q-table by all zeros.\n",
        "\n",
        "Start exploring actions: \n",
        "\n",
        "For each state, select any one among all possible actions for the current state (S).\n",
        "\n",
        "Travel to the next state (S') as a result of that action (a).\n",
        "\n",
        "For all possible actions from the state (S') select the one with the highest Q-value.\n",
        "\n",
        "Update Q-table values using the equation.\n",
        "\n",
        "Set the next state as the current state.\n",
        "\n",
        "If goal state is reached, then end and repeat the process.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vERIh-OW9ir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode(pick_up):\n",
        "    if pick ==  0:\n",
        "        taxi_row, taxi_column  = 0,0\n",
        "    elif pick == 1:\n",
        "        taxi_row, taxi_column  = 0,3\n",
        "    elif pick == 2:\n",
        "        taxi_row, taxi_column  = 3,0\n",
        "    else: \n",
        "        taxi_row, taxi_column  = 3,3\n",
        "        \n",
        "    return taxi_row, taxi_column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_amFWEjW9iw",
        "colab_type": "text"
      },
      "source": [
        "### Generating Q table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzHRx0gaW9iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_q_table(q_table):\n",
        "    \"\"\"Training the agent\"\"\"\n",
        "\n",
        "    # Hyperparameters\n",
        "    alpha = 0.1\n",
        "    gamma = 0.9\n",
        "    epsilon = 0.1\n",
        "\n",
        "    total_penalties = 0\n",
        "    total_epochs = 0\n",
        "    ##Write your code here\n",
        "    for i in range(1, 100001):\n",
        "        state = env.reset()\n",
        "        epochs, penalties, reward, = 0, 0, 0\n",
        "    \n",
        "        done = False\n",
        "        while not done:\n",
        "            \n",
        "            if random.uniform(0, 1) < epsilon:\n",
        "                action = env.action_space.sample() # Exploring action space\n",
        "            else:\n",
        "                action = np.argmax(q_table[state]) # Exploiting learned values\n",
        "            \n",
        "            next_state, reward, done, info = env.step(action) \n",
        "            old_value = q_table[state, action]\n",
        "            next_max = np.max(q_table[next_state])\n",
        "            new_value = (1 - alpha) * old_value + alpha * (reward + gamma*next_max)\n",
        "            q_table[state, action] = new_value\n",
        "            \n",
        "            if i == 10000:\n",
        "                env.render()\n",
        "            \n",
        "            if done:\n",
        "                break\n",
        "            \n",
        "            elif True:\n",
        "                penalties += 1\n",
        "   \n",
        "            state = next_state\n",
        "            epochs += 1\n",
        "        total_epochs += epochs\n",
        "        total_penalties += penalties\n",
        "           \n",
        "\n",
        "    print(\"q_table Created.\\n\")\n",
        "    #print('Total Penalties: ', total_penalties)\n",
        "    np.save(\"./q_table.npy\", q_table)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LRe8-TcW9i2",
        "colab_type": "text"
      },
      "source": [
        "###  The Q-table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IppgM7sxW9i3",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9df5d5f-8483-4a7e-e35b-3385bb9a9402"
      },
      "source": [
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "generate_q_table(q_table)\n",
        "q_table"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|R: | : :\u001b[42mG\u001b[0m|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (Pickup)\n",
            "+---------+\n",
            "|R: | : :\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "+---------+\n",
            "|R: | : :\u001b[42mG\u001b[0m|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (Pickup)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : : : :\u001b[42m_\u001b[0m|\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : : :\u001b[42m_\u001b[0m: |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|R: | :\u001b[42m_\u001b[0m:G|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : : :\u001b[42m_\u001b[0m: |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : : : : |\n",
            "| : : :\u001b[42m_\u001b[0m: |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : |\u001b[42m_\u001b[0m: |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35m\u001b[42mB\u001b[0m\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35m\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m\u001b[0m: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "q_table Created.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ],\n",
              "       [ 1.62261351,  2.91400926,  1.62261251,  2.91401597,  4.348907  ,\n",
              "        -6.08598366],\n",
              "       [ 4.34890603,  5.94322987,  4.34890671,  5.94322971,  7.7147    ,\n",
              "        -3.05677   ],\n",
              "       ...,\n",
              "       [-1.12875179,  9.68299979, -0.25110817,  1.28622905, -1.73512079,\n",
              "        -1.73215214],\n",
              "       [-2.52095463, -1.10499268, -2.11902451,  2.91401439, -5.35436052,\n",
              "        -5.28994038],\n",
              "       [ 9.17381968,  7.1941436 ,  7.85681049, 17.        ,  1.55785106,\n",
              "         0.197     ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYMzK3BjW9i6",
        "colab_type": "text"
      },
      "source": [
        "### Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hXzle4mSW9i6",
        "colab_type": "code",
        "colab": {},
        "outputId": "e4cb7794-f672-482e-d64f-1ef35b1a2733"
      },
      "source": [
        "f = open(\"./sms.txt\", \"r\")\n",
        "num_of_lines = 1000\n",
        "\n",
        "city = pd.read_csv(\"./city.csv\")\n",
        "loc_dict = create_loc_dict(city)\n",
        "print(loc_dict)\n",
        "\n",
        "org_df = pd.read_csv(\"./org_df.csv\")\n",
        "total_epochs, total_penalties, total_reward, wrong_predictions, right_predictions = 0, 0, 0, 0, 0\n",
        "count = 0\n",
        "\n",
        "line_num = 0\n",
        "for line in f:\n",
        "    #print(line)\n",
        "    \n",
        "    '''For Fetching Variables from Sms'''\n",
        "    origin, destination, time_of_pickup = fetch_pickup_drop(line)\n",
        "    #print('Origin: ',origin, 'destination: ',destination, 'time_of_pick_up: ', time_of_pickup)\n",
        "    \n",
        "    '''true_bool = True for Correct Prediction Else False'''\n",
        "    true_bool = check_pick_up_drop_correction(origin, destination, line_num, org_df) \n",
        "    line_num += 1\n",
        "    if not true_bool:\n",
        "        wrong_predictions += 1\n",
        "        reward = -10\n",
        "        total_reward += reward \n",
        "        total_penalties += 1\n",
        "    else:\n",
        "        right_predictions += 1\n",
        "        \n",
        "    '''Setting Random State'''\n",
        "    rand_state = env.reset()\n",
        "    taxi_row, taxi_column, pick, drop = env.decode(rand_state)\n",
        "    #print('Random State Generated:\\n', taxi_row, taxi_column, pick, drop)\n",
        "    \n",
        "    '''Setting Env Parameter Based on Fetched PickUp and Drop and Return'''\n",
        "    pick = loc_dict[origin]\n",
        "    drop = loc_dict[destination]\n",
        "    taxi_row, taxi_column = decode(pick)\n",
        "    \n",
        "    state = env.encode(taxi_row, taxi_column, int(pick), int(drop))\n",
        "    env.s = state\n",
        "    #taxi_row, taxi_column, pick, drop = env.decode(state)\n",
        "    #print(' State Generated:\\n', taxi_row, taxi_column, pick, drop)\n",
        "    \n",
        "    '''Loading trained q_table for evaluation'''\n",
        "    q_table = np.load(\"./q_table.npy\")\n",
        "    \n",
        "    \"\"\"Evaluate agent's performance after Q-learning\"\"\"\n",
        "\n",
        "    epochs, penalties, Reward = 0, 0, 0\n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        \n",
        "        action = np.argmax(q_table[state])\n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        \n",
        "        if done:\n",
        "            pass\n",
        "       \n",
        "        else:\n",
        "            penalties += 1\n",
        "        \n",
        "        total_reward += reward\n",
        "        state = new_state\n",
        "        epochs += 1\n",
        "        \n",
        "    \n",
        "    total_penalties += penalties\n",
        "    total_epochs += epochs\n",
        "    \n",
        "    \n",
        "print(f\"Results after {num_of_lines} episodes:\")\n",
        "print(f\"Average timesteps per episode: {total_epochs / num_of_lines}\")\n",
        "print(f\"Average penalties per episode: {total_penalties / num_of_lines}\")\n",
        "print(f\"Total number of wrong predictions is: {wrong_predictions} and right predictions is :{right_predictions}\", )\n",
        "print(\"Total Reward is\", total_reward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dwarka sector 23': 0, 'dwarka sector 21': 1, 'hauz khaas': 2, 'airport': 3}\n",
            "Results after 1000 episodes:\n",
            "Average timesteps per episode: 8.925\n",
            "Average penalties per episode: 7.925\n",
            "Total number of wrong predictions is: 0 and right predictions is :1000\n",
            "Total Reward is 12075\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}